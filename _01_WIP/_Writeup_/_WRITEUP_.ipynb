{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Writeup | Behavioral Cloning**   \n",
    "5 min read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract —** this notebook is the writeup of the Behavioral Cloning project as part of the SELF-DRIVING CAR nanodegree program. We apply Deep Learning to clone the behavior of a human driver by getting training data from examples of human driving in a simulator. Then these data feed into a convolutional neural network (CNN) to map features from camera images directly to steering commands. This way the CNN learns to predict the appropriate steering angle when the car drives in autonomous mode in the simulator.   \n",
    "\n",
    "The goals of this project are broken down into the following steps:   \n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report\n",
    "\n",
    "**Note:** the architecture has been inspired by the [nvidia neural network](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) before being tweaked a bit using the [Keras](https://keras.io/) deep learning library with Tensorflow backend. The convolutional neural network has been trained only with the sample data provided by Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Rubric Points   \n",
    "*Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.*   \n",
    "\n",
    "### Files Submitted & Code Quality\n",
    "\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* tools.py containing the generator to pull pieces of the data and process them on the fly \n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "#### 2. Submission includes functional code\n",
    "Using the Udacity provided simulator and a modified version of the drive.py file, the car can be driven autonomously around the track by executing \n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py and tools.py files contains the code for training and saving the convolution neural network. The files show the pipeline I used for training and validating the model, and they contain comments to explain how the code works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. An appropriate model architecture has been employed\n",
    "\n",
    "There are the following layers : a normalization layer, 3 convolutional2D layers, 1 flatten layer and 4 fully-connected layers. ELU ([Exponential linear unit](https://www.quora.com/How-does-ELU-activation-function-help-convergence-and-whats-its-advantages-over-ReLU-or-sigmoid-or-tanh-function)) activation functions are added at each convolutional2D and fully-connected layers. The dropout regularization technique is inserted between the last convolutional2D layer and the flatten layer.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [final model](https://github.com/davisjazz/SDC_PRJ03_Cloning/blob/develop/_00_BSF/_Coding_/_1_pre-train/BSF_model_171203-2024.py) consisted of the following layers:   \n",
    "\n",
    "| Layer         \t\t  |     Description\t        \t\t\t\t         |   \n",
    "|:-----------------------:|:------------------------------------------------:|    \n",
    "| input         \t\t  | 32 x 155 x 3 \t\t\t\t\t\t\t         |      \n",
    "| normalization           | lambda x: x/255.0-0.5                            |   \n",
    "| convolution2D        \t  | { filter: 16 ; stride: 2x2 ; kernel size : 5x5 } |   \n",
    "| activation function\t  | ELU (Exponential linear unit)                    |   \n",
    "| convolution2D        \t  | { filter: 32 ; stride: 2x2 ; kernel size : 5x5 } |   \n",
    "| activation function\t  | ELU                     \t\t\t             |   \n",
    "| convolution2D        \t  | { filter: 64 ; stride: 2x2 ; kernel size : 5x5 } |   \n",
    "| activation function\t  | ELU                     \t\t\t             |   \n",
    "| regularization \t\t  | dropout(keep_prob = 0.5)  \t\t\t             |   \n",
    "| flatten\t      \t\t  |    \t\t\t    \t\t\t        \t         |   \n",
    "| fully connected (Dense) | { 100 hidden units }   \t\t\t                 |   \n",
    "| activation function\t  | ELU                     \t\t\t             |   \n",
    "| fully connected (Dense) | { 50 hidden units }   \t\t\t                 |   \n",
    "| activation function\t  | ELU                     \t\t\t             |   \n",
    "| fully connected (Dense) | { 10 hidden units }   \t\t\t                 |   \n",
    "| activation function\t  | ELU                     \t\t\t             |   \n",
    "| fully connected (Dense) | { 1 hidden unit }   \t\t\t                 |   \n",
    "\n",
    "\n",
    "**Note:** I do not use a max pooling layer. For more details, read the [Geoffrey Hinton's comments on max pooling](https://mirror2image.wordpress.com/2014/11/11/geoffrey-hinton-on-max-pooling-reddit-ama/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "The model contains one dropout layer in order to reduce overfitting.\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting (code line 44-50). The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually (model.py line 70) except for the transfer learning phase where I changed the default learning rate from 1e-3 to 8.5e-4.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 4. Appropriate training data\n",
    "\n",
    "I tried to collect data using the keyboard arrows but it was very challenging and at the end the data were not as good as expected to train properly the neural network. Then the sample data provided by Udacity have been used to train the model. In order to keep the vehicle driving on the road they have been also preprocessed and jittered before fine tunning the neural network. Jitteration and preprocessing techniques have shown to be very effective ways to improve the neural network performances as I have learnt in the Traffic Sign Recognition project.  \n",
    "\n",
    "For details about how I created the training data, see the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "It was an iterative approach with much trial and error.\n",
    "\n",
    "##### 1.1. The first attempt: Nvidia convolution neural network\n",
    "Initially I used a convolution neural network model similar to the [Nvidia CNN](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) as discribed below:\n",
    "![fig.1](https://raw.githubusercontent.com/davisjazz/SDC_PRJ03_Cloning/develop/_01_WIP/_Writeup_/_image_/_model_SPIN.PNG)   \n",
    "\n",
    "The Nvidia model might be appropriate because it learns to drive in track with or without lane markings or in areas with unclear visual guidance such as on unpaved roads. It automatically learns to detecte useful road features with only the steering angle as the training signal.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 1.2. Overfitting and countermeasure   \n",
    "In order to gauge how well the model was working, I split the image and steering angle data into a training and validation set. This first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting. \n",
    "\n",
    "To combat the overfitting, I used the following techniques:\n",
    "- train the model with more data (augmentation and jitteration)\n",
    "- stop the training when the loss has stopped improving\n",
    "- add a dropout layer as a regularization technique\n",
    "\n",
    "I also removed all images and the related steering angles driving the car off the track from the sample dataset.\n",
    "\n",
    "If I would have more time, I would implement [the cross-validation technique](https://github.com/keras-team/keras/issues/1711) as well. But [the vehicle could stay on the track one](https://youtu.be/uxNCMQ3gk-Q) when the model was tested by running it through the simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. Fine tuning   \n",
    "There were a few spots where the vehicle drove on the lane line of the track. To improve the driving behavior in these cases, I first tried to modify the convolutional neural network by removing a few convolutional2D and then I tweaked it.   \n",
    "\n",
    "At first sight, [the car behavior was dramatically improved](https://youtu.be/_FEcHhhy9lc) by driving perfectly well in the center of the track from the beginning, then over the brige, passing successfully the first turn with its dirty border but it drove off the track in the second turn.   \n",
    "\n",
    "From that point, I have fine tuned the model with more jittered data and I modified the compensation rate of the steering angle.\n",
    "\n",
    "At the end of the process, [the vehicle is able to drive autonomously around the track without leaving the road](https://youtu.be/McrmB3ZIA18)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VOS ETES ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "The sample data provided by Udacity has been used to train the model.\n",
    "\n",
    "##### 3.1. Data exploration\n",
    "\n",
    "The sample data is imbalanced as it is shown in figure 2 below:\n",
    "\n",
    "*fig.2: number of occurence per steering angle value*\n",
    "![fig.2](https://raw.githubusercontent.com/davisjazz/SDC_PRJ03_Cloning/develop/_01_WIP/_Writeup_/_image_/_data_distrib_sample_ori.png)\n",
    "\n",
    "There are 8035\n",
    "I mean that there is quite a concentration of steering angles of 0 degree. In this case, the value of mean_squared_error metric might be excellent on paper but it is only reflecting the underlying steering angle distribution. Consequently, the model will have the tendency to decide that the best thing to do is to always predict a steering angle of 0 degree. It explains why the car goes off the track at the first turn when the model is trained with the sample data as it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to remedy this problem, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VOS ETES ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "look at the data and cleverly decide that the best thing to do is to always predict “Class-3” and achieve high accuracy\n",
    "secondly, the amount of data might be not sufficient for the model to generalise well in production with new data\n",
    "To add more data to the the data set, I combined the two following techniques:\n",
    "\n",
    "images are randomly picked and perturbed in position ([-2,2] pixels)\n",
    "then they are pertubed in rotation ([-15,+15] degrees)\n",
    "Notes:\n",
    "\n",
    "in addition, I also tried to use the bounding box to crop the images and then perturbing them in scale ([.9,1.1] ratio). I got an accuracy around 93%, far below the human performance of 98.81%. I removed this last part and I get a better result at the end\n",
    "the observation of the training set in fig.6 shows the data set is a stack of several series of 30 similar images with usually increasing scale. It is for that reason I did not implement the simple perturbation in scale\n",
    "there are 21 traffic signs that have a horizontal or a vertical axis of symmetry. Consequently, they are invariant to horizontal or vertical flipping. This technic would be implemented to add more data to the data set in the future sprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "I then recorded the vehicle recovering from the left side and right sides of the road back to center so that the vehicle would learn to .... These images show what a recovery looks like starting from ... :\n",
    "\n",
    "![alt text][image3]\n",
    "![alt text][image4]\n",
    "![alt text][image5]\n",
    "\n",
    "Then I repeated this process on track two in order to get more data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "To augment the data sat, I also flipped images and angles thinking that this would ... For example, here is an image that has then been flipped:\n",
    "\n",
    "![alt text][image6]\n",
    "![alt text][image7]\n",
    "\n",
    "Etc ....\n",
    "\n",
    "After the collection process, I had X number of data points. I then preprocessed this data by ...\n",
    "\n",
    "\n",
    "I finally randomly shuffled the data set and put Y% of the data into a validation set. \n",
    "\n",
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting. The ideal number of epochs was Z as evidenced by ... I used an adam optimizer so that manually training the learning rate wasn't necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VOS ETES ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "I then recorded the vehicle recovering from the left side and right sides of the road back to center so that the vehicle would learn to .... These images show what a recovery looks like starting from ... :\n",
    "\n",
    "![alt text][image3]\n",
    "![alt text][image4]\n",
    "![alt text][image5]\n",
    "\n",
    "Then I repeated this process on track two in order to get more data points.\n",
    "\n",
    "To augment the data sat, I also flipped images and angles thinking that this would ... For example, here is an image that has then been flipped:\n",
    "\n",
    "![alt text][image6]\n",
    "![alt text][image7]\n",
    "\n",
    "Etc ....\n",
    "\n",
    "After the collection process, I had X number of data points. I then preprocessed this data by ...\n",
    "\n",
    "\n",
    "I finally randomly shuffled the data set and put Y% of the data into a validation set. \n",
    "\n",
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting. The ideal number of epochs was Z as evidenced by ... I used an adam optimizer so that manually training the learning rate wasn't necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ANNEXE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "My model is an adaptation of the [nvidia architecture](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). \n",
    ">![fig.1](https://raw.githubusercontent.com/davisjazz/SDC_PRJ03_Cloning/develop/_01_WIP/_Writeup_/_model_1%20SPIN_2%20BSF.png)\n",
    "\n",
    "My model consists of *a convolution neural network with 3x3 filter sizes and depths between 32 and 128 (model.py lines 18-24)*. It is an adaptation of the [nvidia architecture](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf)\n",
    "\n",
    "*The model includes ELU layers to introduce nonlinearity (code line 20), and the data is normalized in the model using a Keras lambda layer (code line 18)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
